# üöÄ Guia de Instala√ß√£o - CUDA 11.8 e Cache Local

## Resumo

Este projeto foi configurado para usar:
- **PyTorch com CUDA 11.8** (GPU acceleration)
- **Cache local do pip** dentro do projeto (`pip-cache/`)
- **Python da venv SEMPRE** (nunca Python global)

---

## ‚öôÔ∏è Instala√ß√£o Autom√°tica

Execute o script de inicializa√ß√£o:

### Windows
```bash
run.bat
```

### Linux/Mac
```bash
./run.sh
```

O script vai:
1. ‚úÖ Criar/ativar venv
2. ‚úÖ Instalar PyTorch com CUDA 11.8 (com cache local)
3. ‚úÖ Instalar outras depend√™ncias
4. ‚úÖ Iniciar a aplica√ß√£o

---

## üì¶ Instala√ß√£o Manual (se necess√°rio)

### 1. Criar ambiente virtual
```bash
python -m venv venv
```

### 2. Ativar venv

**Windows:**
```bash
venv\Scripts\activate.bat
```

**Linux/Mac:**
```bash
source venv/bin/activate
```

### 3. Instalar PyTorch com CUDA 11.8

**COM cache local:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --cache-dir pip-cache
```

**SEM cache local:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 4. Instalar demais depend√™ncias

```bash
pip install -r requirements.txt --cache-dir pip-cache
```

---

## üîç Verificar CUDA

Execute:

```bash
python -c "import torch; print('PyTorch:', torch.__version__); print('CUDA Available:', torch.cuda.is_available()); print('Device:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')"
```

Esperado:
```
PyTorch: 2.7.1+cu118
CUDA Available: True
Device: NVIDIA GeForce GTX 3060 (ou similar)
```

---

## üíæ Cache Local do pip

Os downloads do pip s√£o armazenados em `pip-cache/` dentro do projeto.

**Limpar cache:**
```bash
pip cache purge
```

**Ou manualmente:**
```bash
rmdir /s pip-cache  # Windows
rm -rf pip-cache    # Linux/Mac
```

---

## üîÑ Reinstalar Tudo do Zero

### Windows
```bash
run.bat --reinstall
```

### Linux/Mac
```bash
./run.sh --reinstall
```

Ou manualmente:
```bash
rmdir /s venv           # Windows: rmdir /s /q venv
rm -rf venv             # Linux/Mac
pip cache purge
python -m venv venv
# Ativar venv e seguir passos 3-4 acima
```

---

## ‚ö†Ô∏è Problemas Comuns

### PyTorch ainda em CPU
**Causa:** Vers√£o errada foi instalada

**Solu√ß√£o:**
```bash
pip uninstall torch torchvision torchaudio -y
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 --force-reinstall --no-cache-dir
```

### CUDA dispon√≠vel mas n√£o est√° sendo usado
**Causa:** C√≥digo pode estar usando CPU explicitamente

**Solu√ß√£o:** Verificar `ai/context_analyzer.py` e `audio/transcriber.py`

Ambos j√° t√™m detec√ß√£o autom√°tica:
```python
self.device = "cuda" if torch.cuda.is_available() else "cpu"
```

### Download muito lento
**Causa:** Rede lenta ou √≠ndice PyTorch congestionado

**Solu√ß√£o:** Use cache local (j√° configurado) ou tente novamente

---

## üìã Arquivo de Configura√ß√£o

- `requirements.txt` - Depend√™ncias padr√£o (PyTorch n√£o inclu√≠do)
- `requirements-cuda.txt` - Instru√ß√µes para CUDA 11.8
- `run.bat` - Script de inicializa√ß√£o (Windows)
- `run.sh` - Script de inicializa√ß√£o (Linux/Mac)

---

## üéØ O que foi feito

‚úÖ Todos os scripts usam Python da **venv SEMPRE**
‚úÖ Cache local do pip configurado (`pip-cache/`)
‚úÖ PyTorch com CUDA 11.8 configurado
‚úÖ Detec√ß√£o autom√°tica de CUDA em ContextAnalyzer
‚úÖ Detec√ß√£o autom√°tica de CUDA em Transcriber (Whisper)
‚úÖ run.bat com prompt interativo (op√ß√µes de limpeza, reinstala√ß√£o, etc)
‚úÖ run.sh com m√™me funcionalidade para Unix

---

**D√∫vidas?** Verifique os logs em `logs/app.log`
